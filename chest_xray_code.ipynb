{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHEST-XRAY DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-18T06:26:40.813443Z",
     "iopub.status.busy": "2024-02-18T06:26:40.812981Z",
     "iopub.status.idle": "2024-02-18T06:26:40.820406Z",
     "shell.execute_reply": "2024-02-18T06:26:40.818946Z",
     "shell.execute_reply.started": "2024-02-18T06:26:40.813408Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:26:40.822960Z",
     "iopub.status.busy": "2024-02-18T06:26:40.822484Z",
     "iopub.status.idle": "2024-02-18T06:26:40.832874Z",
     "shell.execute_reply": "2024-02-18T06:26:40.831975Z",
     "shell.execute_reply.started": "2024-02-18T06:26:40.822920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:26:40.835455Z",
     "iopub.status.busy": "2024-02-18T06:26:40.834608Z",
     "iopub.status.idle": "2024-02-18T06:26:40.845108Z",
     "shell.execute_reply": "2024-02-18T06:26:40.844268Z",
     "shell.execute_reply.started": "2024-02-18T06:26:40.835413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Preprocess the dataset\n",
    "def load_dataset(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        label_dir = os.path.join(directory, label)\n",
    "        for image_file in os.listdir(label_dir):\n",
    "            image_path = os.path.join(label_dir, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, (256, 256))  # Resize the images to a consistent size\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:26:40.847493Z",
     "iopub.status.busy": "2024-02-18T06:26:40.846351Z",
     "iopub.status.idle": "2024-02-18T06:26:40.860404Z",
     "shell.execute_reply": "2024-02-18T06:26:40.859343Z",
     "shell.execute_reply.started": "2024-02-18T06:26:40.847448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "val_dir = os.path.join(data_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:26:40.863445Z",
     "iopub.status.busy": "2024-02-18T06:26:40.862978Z",
     "iopub.status.idle": "2024-02-18T06:28:29.456232Z",
     "shell.execute_reply": "2024-02-18T06:28:29.455372Z",
     "shell.execute_reply.started": "2024-02-18T06:26:40.863404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = load_dataset(train_dir)\n",
    "x_test, y_test = load_dataset(test_dir)\n",
    "x_val, y_val = load_dataset(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:28:29.458215Z",
     "iopub.status.busy": "2024-02-18T06:28:29.457329Z",
     "iopub.status.idle": "2024-02-18T06:28:31.387137Z",
     "shell.execute_reply": "2024-02-18T06:28:31.386148Z",
     "shell.execute_reply.started": "2024-02-18T06:28:29.458183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Normalize the pixel values\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_val = x_val.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:28:31.388810Z",
     "iopub.status.busy": "2024-02-18T06:28:31.388416Z",
     "iopub.status.idle": "2024-02-18T06:28:31.409112Z",
     "shell.execute_reply": "2024-02-18T06:28:31.408127Z",
     "shell.execute_reply.started": "2024-02-18T06:28:31.388782Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert string labels to numeric representations\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "y_val = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:28:31.410532Z",
     "iopub.status.busy": "2024-02-18T06:28:31.410181Z",
     "iopub.status.idle": "2024-02-18T06:28:32.966928Z",
     "shell.execute_reply": "2024-02-18T06:28:32.965117Z",
     "shell.execute_reply.started": "2024-02-18T06:28:31.410502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T06:28:32.970430Z",
     "iopub.status.busy": "2024-02-18T06:28:32.970029Z",
     "iopub.status.idle": "2024-02-18T06:28:33.575219Z",
     "shell.execute_reply": "2024-02-18T06:28:33.571329Z",
     "shell.execute_reply.started": "2024-02-18T06:28:32.970398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Build the CNN model\n",
    "model_CNN = Sequential()\n",
    "model_CNN.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model_CNN.add(MaxPooling2D((2, 2)))\n",
    "model_CNN.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_CNN.add(MaxPooling2D((2, 2)))\n",
    "model_CNN.add(Flatten())\n",
    "model_CNN.add(Dense(64, activation='relu'))\n",
    "model_CNN.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Train the model\n",
    "model_CNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model_CNN.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T07:06:19.418679Z",
     "iopub.status.busy": "2024-02-18T07:06:19.417346Z",
     "iopub.status.idle": "2024-02-18T07:06:19.423637Z",
     "shell.execute_reply": "2024-02-18T07:06:19.422832Z",
     "shell.execute_reply.started": "2024-02-18T07:06:19.418633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC\n",
    "# Assuming model_CNN is already trained\n",
    "# Extract features from the CNN model\n",
    "#from tensorflow.keras import Model\n",
    "\n",
    "# Define a new model to extract features from the CNN layers\n",
    "#feature_extractor = Model(inputs=model_CNN.input, outputs=model_CNN.get_layer('flatten').output)\n",
    "\n",
    "# Extract features from the trained CNN for train, validation, and test sets\n",
    "#x_train_features = feature_extractor.predict(x_train)\n",
    "#x_val_features = feature_extractor.predict(x_val)\n",
    "#x_test_features = feature_extractor.predict(x_test)\n",
    "\n",
    "\n",
    "# Initialize and train the SVM\n",
    "#svm = SVC(kernel='linear')  # You can change the kernel as per your requirement\n",
    "#svm.fit(x_train_features, y_train)\n",
    "\n",
    "# Evaluate SVM on the validation set\n",
    "#svm_val_accuracy = svm.score(x_val_features, y_val)\n",
    "#print('SVM Validation Accuracy:', svm_val_accuracy)\n",
    "\n",
    "# Evaluate SVM on the test set\n",
    "#svm_test_accuracy = svm.score(x_test_features, y_test)\n",
    "#print('SVM Test Accuracy:', svm_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img_width = 256\n",
    "img_height  = 256\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_generator1 = test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "loss1, accuracy1 = model_CNN.evaluate(test_generator1)\n",
    "print('Test Loss:', loss1)\n",
    "print('Test Accuracy:', accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Predict probabilities on validation data\n",
    "y_pred_prob = model_CNN.predict(x_val)\n",
    "# Threshold probabilities to get predicted classes\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  # Importing matplotlib.pyplot module\n",
    "\n",
    "# Get the predicted probabilities for the validation set\n",
    "y_pred_prob = model_CNN.predict(x_val)\n",
    "# Convert probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=label_encoder.classes_, \n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Generate predictions for the validation set\n",
    "y_pred = model_CNN.predict(x_val)\n",
    "y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Calculate F1 score\n",
    "f1score = f1_score(y_val, y_pred)\n",
    "\n",
    "print('F1 Score:', f1score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Step 4: Make predictions on the validation set\n",
    "y_pred_val = model_CNN.predict(x_val)\n",
    "\n",
    "# Step 5: Compute ROC curve and AUC for each class\n",
    "fpr_normal, tpr_normal, _ = roc_curve(y_val, y_pred_val)\n",
    "roc_auc_normal = auc(fpr_normal, tpr_normal)\n",
    "\n",
    "fpr_pneumonia, tpr_pneumonia, _ = roc_curve(1 - y_val, 1 - y_pred_val)  # Inverting labels for pneumonia class\n",
    "roc_auc_pneumonia = auc(fpr_pneumonia, tpr_pneumonia)\n",
    "\n",
    "# Step 6: Plot ROC curve for both classes\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_normal, tpr_normal, color='blue', lw=2, label='Normal (AUC = %0.2f)' % roc_auc_normal)\n",
    "plt.plot(fpr_pneumonia, tpr_pneumonia, color='red', lw=2, label='Pneumonia (AUC = %0.2f)' % roc_auc_pneumonia)\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-18T07:06:42.744880Z",
     "iopub.status.idle": "2024-02-18T07:06:42.745268Z",
     "shell.execute_reply": "2024-02-18T07:06:42.745105Z",
     "shell.execute_reply.started": "2024-02-18T07:06:42.745087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy versus epoch\n",
    "beingsaved = plt.figure(figsize=(7, 5))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('CNN Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "beingsaved.savefig('Accuracy.png', format='png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Plot loss versus epoch\n",
    "beingsaved = plt.figure(figsize=(7, 5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('CNN Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "beingsaved.savefig('Loss.png', format='png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-18T07:06:42.747035Z",
     "iopub.status.idle": "2024-02-18T07:06:42.747437Z",
     "shell.execute_reply": "2024-02-18T07:06:42.747246Z",
     "shell.execute_reply.started": "2024-02-18T07:06:42.747228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the number of folds\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# Lists to store accuracy and loss for each fold\n",
    "fold_accuracy = []\n",
    "fold_val_accuracy = []\n",
    "fold_loss = []\n",
    "fold_val_loss = []\n",
    "\n",
    "# Loop through each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(x_train, y_train), 1):\n",
    "    print(f'Fold {fold}/{num_folds}')\n",
    "    \n",
    "    # Split the data into train and validation sets for this fold\n",
    "    x_fold_train, x_fold_val = x_train[train_idx], x_train[val_idx]\n",
    "    y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # Build the CNN model (same as before)\n",
    "    model_CNN = Sequential()\n",
    "    model_CNN.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "    model_CNN.add(MaxPooling2D((2, 2)))\n",
    "    model_CNN.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model_CNN.add(MaxPooling2D((2, 2)))\n",
    "    model_CNN.add(Flatten())\n",
    "    model_CNN.add(Dense(64, activation='relu'))\n",
    "    model_CNN.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model_CNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model for this fold\n",
    "    history = model_CNN.fit(x_fold_train, y_fold_train, epochs=20, batch_size=32, validation_data=(x_fold_val, y_fold_val))\n",
    "\n",
    "    # Evaluate model on validation data for this fold\n",
    "    loss, accuracy = model_CNN.evaluate(x_fold_val, y_fold_val)\n",
    "    fold_loss.append(loss)\n",
    "    fold_accuracy.append(accuracy)\n",
    "\n",
    "    # Evaluate model on test data for this fold\n",
    "    val_loss, val_accuracy = model_CNN.evaluate(x_val, y_val)\n",
    "    fold_val_loss.append(val_loss)\n",
    "    fold_val_accuracy.append(val_accuracy)\n",
    "\n",
    "    # Plot accuracy versus epoch for this fold\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'CNN Model Accuracy - Fold {fold}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "    plt.savefig(f'Accuracy_fold_{fold}.png', format='png', dpi=600, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot loss versus epoch for this fold\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'CNN Model Loss - Fold {fold}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    plt.savefig(f'Loss_fold_{fold}.png', format='png', dpi=600, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# Print the mean and standard deviation of metrics across all folds\n",
    "print(f'Mean Accuracy across {num_folds} folds:', np.mean(fold_accuracy))\n",
    "print(f'Std Deviation of Accuracy across {num_folds} folds:', np.std(fold_accuracy))\n",
    "print(f'Mean Validation Accuracy across {num_folds} folds:', np.mean(fold_val_accuracy))\n",
    "print(f'Std Deviation of Validation Accuracy across {num_folds} folds:', np.std(fold_val_accuracy))\n",
    "print(f'Mean Loss across {num_folds} folds:', np.mean(fold_loss))\n",
    "print(f'Std Deviation of Loss across {num_folds} folds:', np.std(fold_loss))\n",
    "print(f'Mean Validation Loss across {num_folds} folds:', np.mean(fold_val_loss))\n",
    "print(f'Std Deviation of Validation Loss across {num_folds} folds:', np.std(fold_val_loss))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
